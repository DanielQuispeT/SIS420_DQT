{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"GsGje7In4c4S"},"source":["# Ejercicio2, Redes Neuronales EMNIST\n","\n","Nombre: Quispe Taboada Daniel <br>\n","Dataset: ['EMNIST'](https://www.kaggle.com/datasets/keshavsharma2/emnist)"]},{"cell_type":"code","execution_count":144,"metadata":{"executionInfo":{"elapsed":307,"status":"ok","timestamp":1671227466037,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"JUiJJjo2y38H"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":145,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671227466330,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"k1a64CQzzV-v"},"outputs":[],"source":["def displayData(X, example_width=None, figsize=(10, 10)):\n","    \"\"\"\n","    Muestra datos 2D almacenados en X en una cuadrícula apropiada.\n","    \"\"\"\n","    # Calcula filas, columnas\n","    if X.ndim == 2:\n","        m, n = X.shape\n","    elif X.ndim == 1:\n","        n = X.size\n","        m = 1\n","        X = X[None]  # Promocionar a una matriz bidimensional\n","    else:\n","        raise IndexError('La entrada X debe ser 1 o 2 dimensinal.')\n","\n","    example_width = example_width or int(np.round(np.sqrt(n)))\n","    example_height = n / example_width\n","\n","    # Calcula el numero de elementos a mostrar\n","    display_rows = int(np.floor(np.sqrt(m)))\n","    display_cols = int(np.ceil(m / display_rows))\n","\n","    fig, ax_array = pyplot.subplots(display_rows, display_cols, figsize=figsize)\n","    fig.subplots_adjust(wspace=0.025, hspace=0.025)\n","\n","    ax_array = [ax_array] if m == 1 else ax_array.ravel()\n","\n","    for i, ax in enumerate(ax_array):\n","        ax.imshow(X[i].reshape(example_width, example_width, order='F'),\n","                  cmap='Greys', extent=[0, 1, 0, 1])\n","        ax.axis('off')"]},{"cell_type":"markdown","metadata":{"id":"if-9iJwVpoCd"},"source":["# El Perceptrón Multicapa - Clasificación"]},{"cell_type":"markdown","metadata":{"id":"rsDrAfTzpoCf"},"source":["### Funciones de activación"]},{"cell_type":"markdown","metadata":{"id":"lmlIcJz0poCf"},"source":["Para la capa oculta de nuestro MLP utilizaremos una función de activación de tipo `relu`, de la cual necesitaremos su derivada."]},{"cell_type":"code","execution_count":146,"metadata":{"ExecuteTime":{"end_time":"2020-08-05T16:49:53.041393Z","start_time":"2020-08-05T16:49:53.024396Z"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1671227466331,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"Ylt5Ds-lpoCg"},"outputs":[],"source":["def relu(x):\n","  return np.maximum(0, x)\n","\n","def reluPrime(x):\n","  return x > 0"]},{"cell_type":"markdown","metadata":{"id":"sUw6qKXYpoCh"},"source":["En cuanto a las funciones de activación que utilizaremos a la salida del MLP, éstas son las que hemos introducido en posts anteriores:\n","\n","- Lineal: usada para regresión (junto a la función de pérdida MSE).\n","- Sigmoid: usada para clasificación binaria (junto a la función de pérdida BCE).\n","- Softmax: usada para clasificación multiclase (junto a la función de pérdida crossentropy, CE)."]},{"cell_type":"code","execution_count":147,"metadata":{"ExecuteTime":{"end_time":"2020-08-05T16:49:53.311543Z","start_time":"2020-08-05T16:49:53.298548Z"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671227466331,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"kCAXtpg0poCj"},"outputs":[],"source":["def linear(x):\n","    return x\n","\n","def sigmoid(x):\n","  return 1 / (1 + np.exp(-x))\n","\n","def softmax(x):\n","    return np.exp(x) / np.exp(x).sum(axis=-1,keepdims=True)"]},{"cell_type":"markdown","metadata":{"id":"0P-WfYM6poCk"},"source":["### Funciones de pérdida"]},{"cell_type":"markdown","metadata":{"id":"XVeDCtSFpoCk"},"source":["Como acabamos de comentar en la sección anterior, estas son las funciones de pérdida que hemos visto hasta ahora para las diferentes tareas."]},{"cell_type":"code","execution_count":148,"metadata":{"ExecuteTime":{"end_time":"2020-08-05T16:49:53.677416Z","start_time":"2020-08-05T16:49:53.673343Z"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671227466331,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"UOh2YiWRpoCk"},"outputs":[],"source":["# Mean Square Error -> usada para regresión (con activación lineal)\n","def mse(y, y_hat):\n","    return np.mean((y_hat - y.reshape(y_hat.shape))**2)\n","\n","# Binary Cross Entropy -> usada para clasificación binaria (con sigmoid)\n","def bce(y, y_hat):\n","    return - np.mean(y.reshape(y_hat.shape)*np.log(y_hat) - (1 - y.reshape(y_hat.shape))*np.log(1 - y_hat))\n","\n","# Cross Entropy (aplica softmax + cross entropy de manera estable) -> usada para clasificación multiclase\n","def crossentropy(y, y_hat):\n","    logits = y_hat[np.arange(len(y_hat)),y]\n","    entropy = - logits + np.log(np.sum(np.exp(y_hat),axis=-1))\n","    return entropy.mean()"]},{"cell_type":"markdown","metadata":{"id":"zEframEupoCl"},"source":["Y sus derivadas"]},{"cell_type":"code","execution_count":149,"metadata":{"ExecuteTime":{"end_time":"2020-08-05T16:49:53.945375Z","start_time":"2020-08-05T16:49:53.925371Z"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1671227466331,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"OkbADrMwpoCl"},"outputs":[],"source":["def grad_mse(y, y_hat):\n","    return y_hat - y.reshape(y_hat.shape)\n","\n","def grad_bce(y, y_hat):\n","    return y_hat - y.reshape(y_hat.shape)\n","\n","def grad_crossentropy(y, y_hat):\n","    answers = np.zeros_like(y_hat)\n","    answers[np.arange(len(y_hat)),y] = 1    \n","    return (- answers + softmax(y_hat)) / y_hat.shape[0]"]},{"cell_type":"markdown","metadata":{"id":"S8mpB03kpoCl"},"source":["### Implementación MLP"]},{"cell_type":"markdown","metadata":{"id":"80ZaIUdnpoCl"},"source":["Ahora que ya tenemos definidas las diferentes funciones de activación y de pérdida que necesitamos, vamos a implementar nuestro MLP de dos capas capaz de llevar a cabo tanto tareas de regresión como de clasificación. Del mismo modo que ya hicimos con el `Perceptrón`, definiremos una clase base que servirá para la implementación de las clases particulares para cada caso."]},{"cell_type":"code","execution_count":150,"metadata":{"ExecuteTime":{"end_time":"2020-08-05T16:49:54.342062Z","start_time":"2020-08-05T16:49:54.325063Z"},"code_folding":[3,14,20,55],"executionInfo":{"elapsed":339,"status":"ok","timestamp":1671227466667,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"fMgAW0yxpoCl"},"outputs":[],"source":["# clase base MLP \n","\n","class MLP():\n","  def __init__(self, D_in, H, D_out, loss, grad_loss, activation):\n","    # pesos de la capa 1\n","    self.w1, self.b1 = np.random.normal(loc=0.0,\n","                                  scale=np.sqrt(2/(D_in+H)),\n","                                  size=(D_in, H)), np.zeros(H)\n","    # pesos de la capa 2\n","    self.w2, self.b2 = np.random.normal(loc=0.0,\n","                                  scale=np.sqrt(2/(H+D_out)),\n","                                  size=(H, D_out)), np.zeros(D_out)\n","    self.ws = []\n","    # función de pérdida y derivada\n","    self.loss = loss\n","    self.grad_loss = grad_loss\n","    # función de activación\n","    self.activation = activation\n","\n","  def __call__(self, x):\n","    # salida de la capa 1\n","    self.h_pre = np.dot(x, self.w1) + self.b1\n","    self.h = relu(self.h_pre)\n","    # salida del MLP\n","    y_hat = np.dot(self.h, self.w2) + self.b2 \n","    return self.activation(y_hat)\n","    \n","  def fit(self, X, Y, epochs = 100, lr = 0.001, batch_size=None, verbose=True, log_each=1):\n","    batch_size = len(X) if batch_size == None else batch_size\n","    batches = len(X) // batch_size\n","    l = []\n","    for e in range(1,epochs+1):     \n","        # Mini-Batch Gradient Descent\n","        _l = []\n","        for b in range(batches):\n","            # batch de datos\n","            x = X[b*batch_size:(b+1)*batch_size]\n","            y = Y[b*batch_size:(b+1)*batch_size] \n","            # salida del perceptrón\n","            y_pred = self(x) \n","            # función de pérdida\n","            loss = self.loss(y, y_pred)\n","            _l.append(loss)        \n","            # Backprop \n","            dldy = self.grad_loss(y, y_pred) \n","            grad_w2 = np.dot(self.h.T, dldy)\n","            grad_b2 = dldy.mean(axis=0)\n","            dldh = np.dot(dldy, self.w2.T)*reluPrime(self.h_pre)      \n","            grad_w1 = np.dot(x.T, dldh)\n","            grad_b1 = dldh.mean(axis=0)\n","            # Update (GD)\n","            self.w1 = self.w1 - lr * grad_w1\n","            self.b1 = self.b1 - lr * grad_b1\n","            self.w2 = self.w2 - lr * grad_w2\n","            self.b2 = self.b2 - lr * grad_b2\n","        l.append(np.mean(_l))\n","        # guardamos pesos intermedios para visualización\n","        self.ws.append((\n","            self.w1.copy(),\n","            self.b1.copy(),\n","            self.w2.copy(),\n","            self.b2.copy()\n","        ))\n","        if verbose and not e % log_each:\n","            print(f'Epoch: {e}/{epochs}, Loss: {np.mean(l):.5f}')\n","\n","  def predict(self, ws, x):\n","    w1, b1, w2, b2 = ws\n","    h = relu(np.dot(x, w1) + b1)\n","    y_hat = np.dot(h, w2) + b2\n","    return self.activation(y_hat)"]},{"cell_type":"code","execution_count":151,"metadata":{"ExecuteTime":{"end_time":"2020-08-05T16:57:40.536617Z","start_time":"2020-08-05T16:57:40.515590Z"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671227466667,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"qpPTIgibpoCm"},"outputs":[],"source":["# MLP para regresión\n","class MLPRegression(MLP):\n","    def __init__(self, D_in, H, D_out):\n","        super().__init__(D_in, H, D_out, mse, grad_mse, linear)\n","\n","# MLP para clasificación binaria\n","class MLPBinaryClassification(MLP):\n","    def __init__(self, D_in, H, D_out):\n","        super().__init__(D_in, H, D_out, bce, grad_bce, sigmoid)\n","\n","# MLP para clasificación multiclase\n","class MLPClassification(MLP):\n","    def __init__(self, D_in, H, D_out):\n","        super().__init__(D_in, H, D_out, crossentropy, grad_crossentropy, linear)"]},{"cell_type":"markdown","metadata":{"id":"-NkSioazpoCm"},"source":["Vamos a probar ahora nuestra implementación para diferentes ejemplos."]},{"cell_type":"markdown","metadata":{"id":"mpif23EypoCr"},"source":["## Clasificación Multiclase"]},{"cell_type":"markdown","metadata":{"id":"OWubBvi-poCr"},"source":["Por último vamos a ver cómo aplicar nuestro modelo para clasificación en multiples clases."]},{"cell_type":"code","execution_count":152,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2119,"status":"ok","timestamp":1671227468783,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"-tK44KKm2FPl","outputId":"364f4ad5-95e7-4924-87cf-bc64b7ce6f3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Para trabajar en colab\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":153,"metadata":{"executionInfo":{"elapsed":1422,"status":"ok","timestamp":1671227470203,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"2J1QKwGsy0TK"},"outputs":[],"source":["# para colab\n","# dataN = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/SegundoPRacial/Data/processed_balanced_test.csv\", sep=',')\n","dataN = pd.read_csv(\"Data/processed_balanced_test.csv\", sep=',')\n","data = dataN.to_numpy()"]},{"cell_type":"code","execution_count":154,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1671227470204,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"Hf7i3izh3ZEV","outputId":"9ead4c57-d30c-44ce-ab71-68c5a9daa571"},"outputs":[{"data":{"text/plain":["(20800, 785)"]},"execution_count":154,"metadata":{},"output_type":"execute_result"}],"source":["dataN.shape"]},{"cell_type":"code","execution_count":155,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1671227470204,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"r6_3RPnL2tSE"},"outputs":[],"source":["X, y = data[:, 1:20000], data[:, 0]\n","salidas = len(np.unique(y))\n","m, n = X.shape"]},{"cell_type":"code","execution_count":156,"metadata":{"ExecuteTime":{"end_time":"2020-08-05T17:05:47.527647Z","start_time":"2020-08-05T17:05:47.393648Z"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1671227470204,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"jFNDTkctpoCr"},"outputs":[],"source":["# X_mean, X_std = X.mean(axis=0), X.std(axis=0)\n","# X_norm = (X - X_mean) / X_std\n","# X_norm = X/255"]},{"cell_type":"code","execution_count":157,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1671227470204,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"99eAPjfd5xtV"},"outputs":[],"source":["def controlador(data):\n","    listaMayor = []\n","    for value in data:\n","        mayor = 0\n","        for index in range( len(value) ):\n","            if( value[index] >= value[mayor]):\n","                mayor = index\n","        listaMayor.append(mayor)\n","    return listaMayor"]},{"cell_type":"code","execution_count":161,"metadata":{"ExecuteTime":{"end_time":"2020-08-05T17:08:01.961788Z","start_time":"2020-08-05T17:08:01.891163Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":646379,"status":"ok","timestamp":1671228651673,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"pDXzCQG_poCr","outputId":"f6e4a7b2-3359-47b7-88dc-67af7021157b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 10/500, Loss: 1.11027\n","Epoch: 20/500, Loss: 0.72752\n","Epoch: 30/500, Loss: 0.53476\n","Epoch: 40/500, Loss: 0.41682\n","Epoch: 50/500, Loss: 0.33884\n","Epoch: 60/500, Loss: 0.28484\n","Epoch: 70/500, Loss: 0.24547\n","Epoch: 80/500, Loss: 0.21557\n","Epoch: 90/500, Loss: 0.19213\n","Epoch: 100/500, Loss: 0.17328\n","Epoch: 110/500, Loss: 0.15780\n","Epoch: 120/500, Loss: 0.14486\n","Epoch: 130/500, Loss: 0.13389\n","Epoch: 140/500, Loss: 0.12447\n","Epoch: 150/500, Loss: 0.11628\n","Epoch: 160/500, Loss: 0.10912\n","Epoch: 170/500, Loss: 0.10278\n","Epoch: 180/500, Loss: 0.09715\n","Epoch: 190/500, Loss: 0.09210\n","Epoch: 200/500, Loss: 0.08755\n","Epoch: 210/500, Loss: 0.08343\n","Epoch: 220/500, Loss: 0.07969\n","Epoch: 230/500, Loss: 0.07627\n","Epoch: 240/500, Loss: 0.07313\n","Epoch: 250/500, Loss: 0.07024\n","Epoch: 260/500, Loss: 0.06757\n","Epoch: 270/500, Loss: 0.06510\n","Epoch: 280/500, Loss: 0.06280\n","Epoch: 290/500, Loss: 0.06066\n","Epoch: 300/500, Loss: 0.05866\n","Epoch: 310/500, Loss: 0.05679\n","Epoch: 320/500, Loss: 0.05504\n","Epoch: 330/500, Loss: 0.05339\n","Epoch: 340/500, Loss: 0.05184\n","Epoch: 350/500, Loss: 0.05037\n","Epoch: 360/500, Loss: 0.04899\n","Epoch: 370/500, Loss: 0.04768\n","Epoch: 380/500, Loss: 0.04644\n","Epoch: 390/500, Loss: 0.04526\n","Epoch: 400/500, Loss: 0.04415\n","Epoch: 410/500, Loss: 0.04308\n","Epoch: 420/500, Loss: 0.04207\n","Epoch: 430/500, Loss: 0.04110\n","Epoch: 440/500, Loss: 0.04018\n","Epoch: 450/500, Loss: 0.03930\n","Epoch: 460/500, Loss: 0.03845\n","Epoch: 470/500, Loss: 0.03764\n","Epoch: 480/500, Loss: 0.03687\n","Epoch: 490/500, Loss: 0.03612\n","Epoch: 500/500, Loss: 0.03541\n"]}],"source":["model = MLPClassification(D_in=n, H=200, D_out=salidas)\n","epochs, lr = 500, 0.8\n","model.fit(X, y, epochs, lr, batch_size=100, log_each=10)"]},{"cell_type":"code","execution_count":164,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":326,"status":"ok","timestamp":1671228696395,"user":{"displayName":"Daniel Quispe Taboada","userId":"05940309157313605164"},"user_tz":240},"id":"pcwbTWZm53-0","outputId":"ea1e54f3-44fd-47d0-c5d1-e3e5ece7a8bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Precision del conjuto de entrenamiento: 99.00%\n"]}],"source":["input_layer_size  = 784\n","numero = 20500\n","XPrueba = X[numero:numero+100, :].copy()\n","peso = [model.w1, model.b1, model.w2, model.b2]\n","prediccion = model.predict(peso, XPrueba)\n","print('Precision del conjuto de entrenamiento: {:.2f}%'.format(np.mean(controlador(prediccion) == y[numero:numero+100]) * 100))"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/juansensio/blog/blob/master/024_mlp_clasificacion/mlp_clasificacion.ipynb","timestamp":1671206634633}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"233.594px"},"toc_section_display":true,"toc_window_display":false},"vscode":{"interpreter":{"hash":"db770a79811cf06dd2eb2d8661a865789fd9658586cf1984ee660fb686aab52b"}}},"nbformat":4,"nbformat_minor":0}
