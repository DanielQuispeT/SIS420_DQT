{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 11, Regresion Logistica One vs All\n",
    "\n",
    "Nombre: Quispe Taboada Daniel <br>\n",
    "Dataset: ['Body performance Data'](https://www.kaggle.com/datasets/kukuroo3/body-performance-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo científico y vectorial para python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot # Libreria para graficos\n",
    "from scipy import optimize # Modulo de optimizacion en scipy\n",
    "\n",
    "# le dice a matplotlib que incruste gráficos en el cuaderno\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataN = pd.read_csv('bodyPerformance.csv', sep=',')\n",
    "dataN['gender'] = dataN['gender'].map({'M': 1, 'F': 2})\n",
    "dataN['class'] = dataN['class'].map({'A': 0, 'B': 1, 'C': 2, 'D': 3})\n",
    "cc = list(dataN.columns)\n",
    "data = dataN.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 4 \n",
    "X, y = data[:, 0:11], data[:, 11].ravel() \n",
    "m, n = X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores de prueba para los parámetros theta\n",
    "theta_t = np.array([-3, -1, 1, 3], dtype=float)\n",
    "\n",
    "# valores de prueba para las entradas\n",
    "X_t = np.concatenate([np.ones((5, 1)), np.arange(1, 16).reshape(5, 3, order='F')/10.0], axis=1)\n",
    "# valores de testeo para las etiquetas\n",
    "y_t = np.array([1, 0, 1, 0, 1])\n",
    "# valores de testeo para el parametro de regularizacion\n",
    "lambda_t = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calcula la sigmoide de z.\n",
    "    \"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrCostFunction(theta, X, y, lambda_):\n",
    "    \"\"\"\n",
    "    Calcula el costo de usar theta como parámetro para la regresión logística regularizada y \n",
    "    el gradiente del costo w.r.t. a los parámetros.\n",
    "    \n",
    "    Parametros\n",
    "    ----------\n",
    "    theta : array_like\n",
    "        Parametro theta de la regresion logistica. Vector de la forma(shape) (n, ). n es el numero de caracteristicas \n",
    "        incluida la intercepcion\n",
    "        \n",
    "    X : array_like\n",
    "        Dataset con la forma(shape) (m x n). m es el numero de ejemplos, y n es el numero de \n",
    "        caracteristicas (incluida la intercepcion).\n",
    "    \n",
    "    y : array_like\n",
    "        El conjunto de etiquetas. Un vector con la forma (shape) (m, ). m es el numero de ejemplos\n",
    "    \n",
    "    lambda_ : float\n",
    "        Parametro de regularización. \n",
    "    \n",
    "    Devuelve\n",
    "    -------\n",
    "    J : float\n",
    "        El valor calculado para la funcion de costo regularizada. \n",
    "    \n",
    "    grad : array_like\n",
    "        Un vector de la forma (shape) (n, ) que es el gradiente de la \n",
    "        función de costo con respecto a theta, en los valores actuales de theta..\n",
    "    \"\"\"\n",
    "    # Inicializa algunos valores utiles\n",
    "    m = y.size\n",
    "    \n",
    "    # convierte las etiquetas a valores enteros si son boleanos\n",
    "    if y.dtype == bool:\n",
    "        y = y.astype(int)\n",
    "    \n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "    \n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "    \n",
    "    temp = theta\n",
    "    temp[0] = 0\n",
    "    \n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
    "    \n",
    "    grad = (1 / m) * (h - y).dot(X) \n",
    "    grad = grad + (lambda_ / m) * temp\n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costo: 4.094713\n",
      "Gradientes: [0.193750, -0.532337, 0.764538, 2.061413]\n"
     ]
    }
   ],
   "source": [
    "J, grad = lrCostFunction(theta_t, X_t, y_t, lambda_t)\n",
    "\n",
    "print('Costo: {:.6f}'.format(J))\n",
    "print('Gradientes: [{:.6f}, {:.6f}, {:.6f}, {:.6f}]'.format(*grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAll(X, y, num_labels, lambda_):\n",
    "    \"\"\"\n",
    "    Trains num_labels logistic regression classifiers and returns\n",
    "    each of these classifiers in a matrix all_theta, where the i-th\n",
    "    row of all_theta corresponds to the classifier for label i.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The input dataset of shape (m x n). m is the number of \n",
    "        data points, and n is the number of features. Note that we \n",
    "        do not assume that the intercept term (or bias) is in X, however\n",
    "        we provide the code below to add the bias term to X. \n",
    "    \n",
    "    y : array_like\n",
    "        The data labels. A vector of shape (m, ).\n",
    "    \n",
    "    num_labels : int\n",
    "        Number of possible labels.\n",
    "    \n",
    "    lambda_ : float\n",
    "        The logistic regularization parameter.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    all_theta : array_like\n",
    "        The trained parameters for logistic regression for each class.\n",
    "        This is a matrix of shape (K x n+1) where K is number of classes\n",
    "        (ie. `numlabels`) and n is number of features without the bias.\n",
    "    \"\"\"\n",
    "    # algunas variables utiles\n",
    "    m, n = X.shape\n",
    "    \n",
    "    all_theta = np.zeros((num_labels, n + 1))\n",
    "\n",
    "    # Agrega unos a la matriz X\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "    for c in np.arange(num_labels):\n",
    "        initial_theta = np.zeros(n + 1)\n",
    "        options = {'maxiter': 50}\n",
    "        res = optimize.minimize(lrCostFunction, \n",
    "                                initial_theta, \n",
    "                                (X, (y == c), lambda_), \n",
    "                                jac=True, \n",
    "                                method='CG',\n",
    "                                options=options) \n",
    "        \n",
    "        all_theta[c] = res.x\n",
    "\n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TUF GAMING\\AppData\\Local\\Temp\\ipykernel_6628\\1892987983.py:46: RuntimeWarning: divide by zero encountered in log\n",
      "  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
      "C:\\Users\\TUF GAMING\\AppData\\Local\\Temp\\ipykernel_6628\\1892987983.py:46: RuntimeWarning: divide by zero encountered in log\n",
      "  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n"
     ]
    }
   ],
   "source": [
    "lambda_ = 0.1\n",
    "all_theta = oneVsAll(X, y, num_labels, lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOneVsAll(all_theta, X):\n",
    "    \"\"\"\n",
    "    Devuelve un vector de predicciones para cada ejemplo en la matriz X.\n",
    "    Tenga en cuenta que X contiene los ejemplos en filas. \n",
    "    all_theta es una matriz donde la i-ésima fila es un vector theta de regresión logística entrenada para la i-ésima clase. \n",
    "    Debe establecer p en un vector de valores de 0..K-1 (por ejemplo, p = [0, 2, 0, 1] \n",
    "    predice clases 0, 2, 0, 1 para 4 ejemplos).\n",
    "    \n",
    "    Parametros\n",
    "    ----------\n",
    "    all_theta : array_like\n",
    "        The trained parameters for logistic regression for each class.\n",
    "        This is a matrix of shape (K x n+1) where K is number of classes\n",
    "        and n is number of features without the bias.\n",
    "    \n",
    "    X : array_like\n",
    "        Data points to predict their labels. This is a matrix of shape \n",
    "        (m x n) where m is number of data points to predict, and n is number \n",
    "        of features without the bias term. Note we add the bias term for X in \n",
    "        this function. \n",
    "    \n",
    "    Devuelve\n",
    "    -------\n",
    "    p : array_like\n",
    "        The predictions for each data point in X. This is a vector of shape (m, ).\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0];\n",
    "    num_labels = all_theta.shape[0]\n",
    "\n",
    "    p = np.zeros(m)\n",
    "\n",
    "    # Add ones to the X data matrix\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del conjuto de entrenamiento: 57.01%\n",
      "La categoria que pertenece los siguientes datos: \n",
      "[[  1.   34.    1.  164.   66.1  19.5  82.  150.   35.9   7.1  51.  180. ]] \n",
      " categoria C\n"
     ]
    }
   ],
   "source": [
    "pred = predictOneVsAll(all_theta, X)\n",
    "print('Precision del conjuto de entrenamiento: {:.2f}%'.format(np.mean(pred == y) * 100))\n",
    "XPrueba = X[13392:13393, :].copy()\n",
    "XPrueba = np.concatenate([np.ones((1, 1)), XPrueba], axis=1)\n",
    "p = np.argmax(sigmoid(XPrueba.dot(all_theta.T)), axis = 1)\n",
    "print('La categoria que pertenece los siguientes datos: ')\n",
    "print(XPrueba, '\\n categoria ',end='')\n",
    "if p == 0:\n",
    "    print('A')\n",
    "elif p == 1:\n",
    "    print('B')\n",
    "elif p == 2:\n",
    "    print('C')\n",
    "elif p == 3:\n",
    "    print('D')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "db770a79811cf06dd2eb2d8661a865789fd9658586cf1984ee660fb686aab52b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
